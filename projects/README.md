# Projects Directory ðŸš€

> Collection of modular computer vision implementations following ML/CV best practices

## ðŸ“‘ Table of Contents

- [Overview](#overview)
- [Project Organization](#project-organization)
- [ML Development Standards](#ml-development-standards)
- [Project Creation Checklist](#project-creation-checklist)

## Overview

This directory contains individual computer vision projects, each following industry-standard ML project organization and best practices for reproducibility, maintainability, and production deployment.

## Project Organization

### Standard Project Structure

```
project-name/
â”œâ”€â”€ README.md          # Project documentation
â”œâ”€â”€ pyproject.toml    # Poetry/project metadata
â”œâ”€â”€ requirements.txt  # Pip requirements (alternative to Poetry)
â”œâ”€â”€ scripts/          # Execution scripts
â”‚   â”œâ”€â”€ train.py      # Training entry point
â”‚   â”œâ”€â”€ evaluate.py   # Evaluation script
â”‚   â”œâ”€â”€ predict.py    # Inference script
â”‚   â””â”€â”€ utils/        # Script utilities
â”œâ”€â”€ configs/          # Configuration files
â”‚   â”œâ”€â”€ model.yaml    # Model architecture
â”‚   â”œâ”€â”€ data.yaml     # Data processing
â”‚   â”œâ”€â”€ train.yaml    # Training parameters
â”‚   â””â”€â”€ experiments/  # Experiment configs
â”œâ”€â”€ data/             # Dataset files (DVC-tracked)
â”‚   â”œâ”€â”€ raw/          # Original data
â”‚   â”‚   â”œâ”€â”€ train/    # Training data
â”‚   â”‚   â”œâ”€â”€ val/      # Validation data
â”‚   â”‚   â””â”€â”€ test/     # Test data
â”‚   â””â”€â”€ processed/    # Processed data
â”œâ”€â”€ src/              # Source code
â”‚   â”œâ”€â”€ data/         # Data processing
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â”œâ”€â”€ transforms.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ models/       # Model implementations
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â”œâ”€â”€ layers.py
â”‚   â”‚   â””â”€â”€ heads/    # Model heads
â”‚   â””â”€â”€ utils/        # Utilities
â”‚       â”œâ”€â”€ metrics.py
â”‚       â”œâ”€â”€ visualization.py
â”‚       â””â”€â”€ logging.py
â”œâ”€â”€ notebooks/        # Jupyter notebooks
â”‚   â”œâ”€â”€ exploration/  # Data exploration
â”‚   â”œâ”€â”€ modeling/     # Model prototyping
â”‚   â””â”€â”€ evaluation/   # Model evaluation
â”œâ”€â”€ ui/               # User interface code
â”‚   â”œâ”€â”€ streamlit/    # Streamlit interface
â”‚   â”‚   â”œâ”€â”€ app.py    # Main Streamlit app
â”‚   â”‚   â”œâ”€â”€ pages/    # App pages
â”‚   â”‚   â””â”€â”€ assets/   # UI resources
â”‚   â””â”€â”€ static/       # Shared static files
â”œâ”€â”€ experiments/      # Experiment tracking
â”‚   â”œâ”€â”€ runs/         # MLflow/experiment runs
â”‚   â”‚   â”œâ”€â”€ baseline/ # Experiment instance
â”‚   â”‚   â””â”€â”€ improved/ # Another experiment
â”‚   â”œâ”€â”€ models/       # Trained models (DVC-tracked)
â”‚   â””â”€â”€ results/      # Evaluation results (DVC-tracked)
â”œâ”€â”€ tests/            # Testing suite
â”‚   â”œâ”€â”€ conftest.py   # Test configuration
â”‚   â”œâ”€â”€ test_data.py  # Data tests
â”‚   â”œâ”€â”€ test_models.py # Model tests
â”‚   â””â”€â”€ test_utils.py # Utility tests
â”œâ”€â”€ docs/             # Documentation
â”‚   â”œâ”€â”€ index.md      # Documentation home
â”‚   â”œâ”€â”€ api/          # API documentation
â”‚   â””â”€â”€ guides/       # User guides
â”œâ”€â”€ artifacts/        # Temporary outputs (not tracked)
â”‚   â”œâ”€â”€ predictions/  # Model predictions
â”‚   â”œâ”€â”€ checkpoints/  # Training checkpoints
â”‚   â””â”€â”€ logs/        # Training logs
â”œâ”€â”€ .dvc/            # DVC configuration
â”‚   â”œâ”€â”€ cache/       # DVC cache (auto-managed)
â”‚   â”œâ”€â”€ tmp/         # DVC temporary files
â”‚   â””â”€â”€ config       # DVC settings
â”œâ”€â”€ .dvcignore       # DVC ignore patterns
â”œâ”€â”€ .env.example     # Environment variables template
â””â”€â”€ .gitignore       # Git ignore patterns
```

### Version Control Strategy

1. **Git-Tracked**

   - Source code (src/)
   - Notebooks (notebooks/)
   - Configuration (configs/)
   - Documentation (docs/)
   - UI code (ui/)
   - Tests (tests/)
   - Small static files

2. **DVC-Tracked**
   - Data files (data/)
   - Trained models (experiments/models/)
   - Important results (experiments/results/)
   - Large binary files
   - Dataset versions
3. **Not Tracked**
   - Temporary files (artifacts/temp/)
   - Cache files (artifacts/cache/)
   - Debug outputs (artifacts/debug/)
   - Local environment files (.env)
   - Build artifacts

### DVC Configuration

```bash
# Initialize DVC
dvc init

# Add remote storage
dvc remote add -d storage s3://bucket/path

# Track data and models
dvc add data/raw
dvc add experiments/models/

# Configure DVC
# .dvcignore
artifacts/          # Ignore temporary outputs
*.pyc              # Ignore Python cache
__pycache__/       # Ignore Python cache directories
.ipynb_checkpoints # Ignore Jupyter checkpoints

# .dvc/config
[core]
    remote = storage
    autostage = true    # Automatically stage DVC changes

[cache]
    type = "hardlink,symlink"  # Efficient storage
    dir = .dvc/cache    # Local cache location
```

Note: DVC manages its own cache in .dvc/cache/. The artifacts/ directory is for temporary outputs that don't need version control:

- predictions/: Model inference outputs
- checkpoints/: Intermediate training checkpoints
- logs/: Training and evaluation logs

### Dependencies Management

1. **Using Poetry (Recommended)**

   ```toml
   # pyproject.toml
   [tool.poetry]
   name = "project-name"
   version = "0.1.0"

   [tool.poetry.dependencies]
   python = "^3.11"
   torch = "^2.3.0"

   [tool.poetry.group.ui.dependencies]
   streamlit = "^1.32.0"
   gradio = "^4.19.0"
   ```

2. **Using Pip (Alternative)**

   ```txt
   # requirements.txt
   torch>=2.3.0
   opencv-python-headless>=5.0.0

   # UI dependencies
   streamlit>=1.32.0
   gradio>=4.19.0
   ```

## Project Creation Checklist

### ðŸš€ Initial Setup

1. **Project Structure**

   ```bash
   # Create project
   mkdir project-name
   cd project-name

   # Initialize version control
   git init
   dvc init

   # Create directories
   mkdir -p src/{data,models,utils}
   mkdir -p scripts
   mkdir -p notebooks/{exploration,modeling,evaluation}
   mkdir -p experiments/{runs,models,results}
   mkdir -p artifacts/{temp,cache,debug}
   mkdir -p docs/{api,guides}
   mkdir -p ui/streamlit/pages
   mkdir -p tests
   ```

2. **Version Control Setup**

   ```bash
   # Configure DVC storage
   dvc remote add -d storage s3://bucket/path

   # Initial data tracking
   dvc add data/raw/
   dvc push
   ```

3. **Environment Setup**

   ```bash
   # Copy environment template
   cp .env.example .env

   # Configure environment
   edit .env  # Add your configurations
   ```

### Best Practices

1. **Data and Model Management**

   - Track data with DVC
   - Version models properly
   - Document data sources
   - Keep artifacts temporary

2. **Development Workflow**

   - Use notebooks for exploration
   - Keep production code in src/
   - Track experiments with MLflow
   - Maintain clean artifacts

3. **Documentation**
   - Clear README.md
   - Detailed docs/
   - API documentation
   - Usage examples

Remember: Keep tracked files clean and temporary outputs in artifacts/! ðŸ’ª
