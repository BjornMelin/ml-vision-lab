# Projects Directory üöÄ

> Collection of modular computer vision implementations following ML/CV best practices

## üìë Table of Contents

- [Overview](#overview)
- [Project Organization](#project-organization)
  - [Standard Project Structure](#standard-project-structure)
  - [Version Control Strategy](#version-control-strategy)
  - [DVC Configuration](#dvc-configuration)
- [ML Development Standards](#ml-development-standards)
- [Project Creation Checklist](#project-creation-checklist)
- [Additional Resources](#additional-resources)

## Overview

This directory contains individual computer vision projects, each following industry-standard ML project organization and best practices for reproducibility, maintainability, and production deployment.

```mermaid
graph TD
    A[projects] --> B[project-name]
    B --> C[src]
    B --> D[scripts]
    B --> E[configs]
    B --> F[data]
    B --> G[experiments]
    B --> H[ui]
    B --> I[docs]
    C --> J[data]
    C --> K[models]
    C --> L[utils]
    D --> M[train.py]
    D --> N[evaluate.py]
    D --> O[predict.py]
    E --> P[model.yaml]
    E --> Q[data.yaml]
    F --> R[raw]
    F --> S[processed]
    G --> T[runs]
    G --> U[models]
    H --> V[streamlit]
    I --> W[api]
```

## Project Organization

### Standard Project Structure

```
project-name/
‚îú‚îÄ‚îÄ README.md          # Project documentation
‚îú‚îÄ‚îÄ pyproject.toml    # Poetry/project metadata
‚îú‚îÄ‚îÄ requirements.txt  # Pip requirements (alternative to Poetry)
‚îú‚îÄ‚îÄ scripts/          # Execution scripts
‚îÇ   ‚îú‚îÄ‚îÄ train.py      # Training entry point
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py   # Evaluation script
‚îÇ   ‚îú‚îÄ‚îÄ predict.py    # Inference script
‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Script utilities
‚îú‚îÄ‚îÄ configs/          # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ model.yaml    # Model architecture
‚îÇ   ‚îú‚îÄ‚îÄ data.yaml     # Data processing
‚îÇ   ‚îú‚îÄ‚îÄ train.yaml    # Training parameters
‚îÇ   ‚îî‚îÄ‚îÄ experiments/  # Experiment configs
‚îú‚îÄ‚îÄ data/             # Dataset files (DVC-tracked)
‚îÇ   ‚îú‚îÄ‚îÄ raw/          # Original data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/    # Training data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val/      # Validation data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test/     # Test data
‚îÇ   ‚îî‚îÄ‚îÄ processed/    # Processed data
‚îú‚îÄ‚îÄ src/              # Source code
‚îÇ   ‚îú‚îÄ‚îÄ data/         # Data processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transforms.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îú‚îÄ‚îÄ models/       # Model implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layers.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ heads/    # Model heads
‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Utilities
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py
‚îÇ       ‚îú‚îÄ‚îÄ visualization.py
‚îÇ       ‚îî‚îÄ‚îÄ logging.py
‚îú‚îÄ‚îÄ notebooks/        # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ exploration/  # Data exploration
‚îÇ   ‚îú‚îÄ‚îÄ modeling/     # Model prototyping
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/   # Model evaluation
‚îú‚îÄ‚îÄ ui/               # User interface code
‚îÇ   ‚îú‚îÄ‚îÄ streamlit/    # Streamlit interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py    # Main Streamlit app
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/    # App pages
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ assets/   # UI resources
‚îÇ   ‚îî‚îÄ‚îÄ static/       # Shared static files
‚îú‚îÄ‚îÄ experiments/      # Experiment tracking
‚îÇ   ‚îú‚îÄ‚îÄ runs/         # MLflow/experiment runs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline/ # Experiment instance
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ improved/ # Another experiment
‚îÇ   ‚îú‚îÄ‚îÄ models/       # Trained models (DVC-tracked)
‚îÇ   ‚îî‚îÄ‚îÄ results/      # Evaluation results (DVC-tracked)
‚îú‚îÄ‚îÄ tests/            # Testing suite
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py   # Test configuration
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py  # Data tests
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py # Model tests
‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py # Utility tests
‚îú‚îÄ‚îÄ docs/             # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ index.md      # Documentation home
‚îÇ   ‚îú‚îÄ‚îÄ api/          # API documentation
‚îÇ   ‚îî‚îÄ‚îÄ guides/       # User guides
‚îú‚îÄ‚îÄ artifacts/        # Temporary outputs (not tracked)
‚îÇ   ‚îú‚îÄ‚îÄ predictions/  # Model predictions
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/  # Training checkpoints
‚îÇ   ‚îî‚îÄ‚îÄ logs/        # Training logs
‚îú‚îÄ‚îÄ .dvc/            # DVC configuration
‚îÇ   ‚îú‚îÄ‚îÄ cache/       # DVC cache (auto-managed)
‚îÇ   ‚îú‚îÄ‚îÄ tmp/         # DVC temporary files
‚îÇ   ‚îî‚îÄ‚îÄ config       # DVC settings
‚îú‚îÄ‚îÄ .dvcignore       # DVC ignore patterns
‚îú‚îÄ‚îÄ .env.example     # Environment variables template
‚îî‚îÄ‚îÄ .gitignore       # Git ignore patterns
```

### Version Control Strategy

```mermaid
graph TD
    A[Version Control] --> B[Git-Tracked]
    A --> C[DVC-Tracked]
    A --> D[Not Tracked]
    B --> E[Source code]
    B --> F[Notebooks]
    B --> G[Configs]
    C --> H[Data files]
    C --> I[Models]
    C --> J[Results]
    D --> K[Temp files]
    D --> L[Cache]
    D --> M[Debug outputs]
```

1. **Git-Tracked**

   - Source code (src/)
   - Notebooks (notebooks/)
   - Configuration (configs/)
   - Documentation (docs/)
   - UI code (ui/)
   - Tests (tests/)
   - Small static files

2. **DVC-Tracked**

   - Data files (data/)
   - Trained models (experiments/models/)
   - Important results (experiments/results/)
   - Large binary files
   - Dataset versions

3. **Not Tracked**
   - Temporary files (artifacts/temp/)
   - Cache files (artifacts/cache/)
   - Debug outputs (artifacts/debug/)
   - Local environment files (.env)
   - Build artifacts

### DVC Configuration

```bash
# Initialize DVC
dvc init

# Add remote storage
dvc remote add -d storage s3://bucket/path

# Track data and models
dvc add data/raw
dvc add experiments/models/

# Configure DVC
# .dvcignore
artifacts/          # Ignore temporary outputs
*.pyc              # Ignore Python cache
__pycache__/       # Ignore Python cache directories
.ipynb_checkpoints # Ignore Jupyter checkpoints

# .dvc/config
[core]
    remote = storage
    autostage = true    # Automatically stage DVC changes

[cache]
    type = "hardlink,symlink"  # Efficient storage
    dir = .dvc/cache    # Local cache location
```

Note: DVC manages its own cache in .dvc/cache/. The artifacts/ directory is for temporary outputs that don't need version control:

- predictions/: Model inference outputs
- checkpoints/: Intermediate training checkpoints
- logs/: Training and evaluation logs

### Dependencies Management

1. **Using Poetry (Recommended)**

```toml
# pyproject.toml
[tool.poetry]
name = "project-name"
version = "0.1.0"

[tool.poetry.dependencies]
python = "^3.11"
torch = "^2.3.0"

[tool.poetry.group.ui.dependencies]
streamlit = "^1.32.0"
gradio = "^4.19.0"
```

2. **Using Pip (Alternative)**

```txt
# requirements.txt
torch>=2.3.0
opencv-python-headless>=5.0.0

# UI dependencies
streamlit>=1.32.0
gradio>=4.19.0
```

## Project Creation Checklist

### üöÄ Initial Setup

1. **Project Structure**

```bash
# Create project
mkdir project-name
cd project-name

# Initialize version control
git init
dvc init

# Create directories
mkdir -p src/{data,models,utils}
mkdir -p scripts
mkdir -p notebooks/{exploration,modeling,evaluation}
mkdir -p experiments/{runs,models,results}
mkdir -p artifacts/{temp,cache,debug}
mkdir -p docs/{api,guides}
mkdir -p ui/streamlit/pages
mkdir -p tests
```

2. **Version Control Setup**

```bash
# Configure DVC storage
dvc remote add -d storage s3://bucket/path

# Initial data tracking
dvc add data/raw/
dvc push
```

3. **Environment Setup**

```bash
# Copy environment template
cp .env.example .env

# Configure environment
edit .env  # Add your configurations
```

### Best Practices

1. **Data and Model Management**

   - Track data with DVC
   - Version models properly
   - Document data sources
   - Keep artifacts temporary

2. **Development Workflow**

   - Use notebooks for exploration
   - Keep production code in src/
   - Track experiments with MLflow
   - Maintain clean artifacts

3. **Documentation**
   - Clear README.md
   - Detailed docs/
   - API documentation
   - Usage examples

## Additional Resources

### üìö Documentation

- [DVC Documentation](https://dvc.org/doc)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [PyTorch Best Practices](https://pytorch.org/docs/stable/notes/best_practices.html)
- [Google ML Best Practices](https://developers.google.com/machine-learning/guides/best-practices)

### üõ†Ô∏è Tools

- [Weights & Biases](https://wandb.ai/) - Experiment tracking
- [PyTorch Lightning](https://lightning.ai/) - ML framework
- [Hydra](https://hydra.cc/) - Configuration management
- [Great Expectations](https://greatexpectations.io/) - Data validation

### üìñ Guides

- [ML Project Organization](https://neptune.ai/blog/how-to-organize-deep-learning-projects-best-practices)
- [Reproducible ML](https://reproducible.ai/)
- [Model Versioning](https://dvc.org/doc/use-cases/versioning-data-and-models)
- [CI/CD for ML](https://neptune.ai/blog/continuous-integration-continuous-deployment-continuous-training-in-machine-learning)

Remember: Keep tracked files clean and temporary outputs in artifacts/! üí™
